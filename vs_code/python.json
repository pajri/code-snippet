{
	// Place your snippets for python here. Each snippet is defined under a snippet name and has a prefix, body and 
	// description. The prefix is what is used to trigger the snippet and the body will be expanded and inserted. Possible variables are:
	// $1, $2 for tab stops, $0 for the final cursor position, and ${1:label}, ${2:another} for placeholders. Placeholders with the 
	// same ids are connected.
	// Example:
	// "Print to console": {
	// 	"prefix": "log",
	// 	"body": [
	// 		"console.log('$1');",
	// 		"$2"
	// 	],
	// 	"description": "Log output to console"
	// }

	//#region COMMON PYTHON
	"ndarray one line": {
		"prefix": "py_config_oneline",
		"body": [
			"np.set_printoptions(linewidth=np.inf)",
			"$2"
		],
		"description": "add config to print ndarray in oneline"
	},
	"for range": {
		"prefix": "py_for_range",
		"body": [
			"for $1 in range($2):",
			"\t$3"
		],
		"description": "create loop using range"
	},
	"use dotenv full": {
		"prefix": "py_dotenv_full",
		"body": [
			"from dotenv import load_dotenv",
			"import os",
			"",
			"# Load variables from .env file",
			"load_dotenv()",
			"",
			"# Access the variables",
			"$1 = os.getenv(\"$2\")",
		],
		"description": "load environment variable using dotnev"
	},
	"autoreload_python_script": {
		"prefix": "autoreload_python_script",
		"body": [
			"%load_ext autoreload",
			"%autoreload 2",
		],
		"description": "autoreload .py when run in .ipynb. put in at the very top of .ipynb file"
	},
	"numpy show all value": {
		"prefix": "numpy_show_all_value",
		"body": [
			"np.set_printoptions(threshold=np.inf)",
			"print($1)",
		],
		"description": "show all value"
	},
	//#endregion COMMON PYTHON

	//#region COMMON MACHINE LEARNING
	"ml common import": {
		"prefix": "ml_common_import",
		"body": [
			"import numpy as np",
			"import pandas as pd",
			"import matplotlib.pyplot as plt",
			"from sklearn.model_selection import train_test_split",
			"from sklearn.datasets import load_iris",
			""
		],
		"description": "common dependencies imported for machine learning purpose"
	},
	"ml common import deeplearning": {
		"prefix": "ml_common_import_deeplearning",
		"body": [
			"# other",
			"import numpy as np",
			"import pandas as pd",
			"import matplotlib.pyplot as plt",
			"",
			"#sklearen",
			"from sklearn.datasets import load_iris",
			"from sklearn.model_selection import train_test_split",
			"from sklearn.preprocessing import LabelEncoder",
			"",
			"# tensorflow",
			"from tensorflow import keras",
			"from keras.models import Sequential",
			"from keras.layers import Dense",
		],
		"description": "common dependencies imported for deep learning learning purpose"
	},
	"ml split_train_test": {
		"prefix": "ml_split_train_test",
		"body": [
			"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)",
			"",
		],
		"description": "split training and test data"
	},
	"ml feature encoding": {
		"prefix": "ml_feature_encoding",
		"body": [
			"label_encoder = LabelEncoder()",
			"$1 = label_encoder.fit_transform($2)",
		],
		"description": "feature encoding for categorical field"
	},
	"ml to categorical": {
		"prefix": "ml_to_categorical",
		"body": [
			"$1 = keras.utils.to_categorical($2)",
		],
		"description": "convert to categorical"
	},
	"ml deep learning layers": {
		"prefix": "ml_deep_learning_layers",
		"body": [
			"model = Sequential()",
			"model.add(Dense(len(X[0]), activation='relu', input_shape=X[0].shape))",
			"model.add(Dense(len(X[0]), activation='relu'))",
			"model.add(Dense(len(y[0,:]), activation='sigmoid',))",
			"",
			"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) "
		],
		"description": "add deep learning layers"
	},
	"ml training": {
		"prefix": "ml_training",
		"body": [
			"log=model.fit(X,y,epochs=$1,batch_size=150) ",
		],
		"description": "training"
	},
	"ml save model": {
		"prefix": "ml_save_model",
		"body": [
			"model.save('$1.keras')",
		],
		"description": "save model"
	},
	"ml load model": {
		"prefix": "ml_load_model",
		"body": [
			"keras.models.load_model('$1.keras')",
		],
		"description": "load model"
	},
	"ml tensorflow enable eager execution": {
		"prefix": "ml_tf_enable_eager_execution",
		"body": [
			"# Enable eager execution (TensorFlow 1.x)",
			"tf.compat.v1.enable_eager_execution()",
			"",
			"# Check if eager execution is enabled",
			"print(\"Is eager execution enabled:\", tf.executing_eagerly())",
		],
		"description": "load model"
	},
	// #endregion COMMON MACHINE LEARNING
	
	//#region PANDAS
	"pandas iterate": {
		"prefix": "pandas_iterate",
		"body": [
			"for row in df.itertuples():",
			"\t$3print(f\"Index: {row.Index}, Name: {row.Name}, Age: {row.Age}, City: {row.City}\")"
		],
		"description": "create loop using range"
	},
	"pandas show all data": {
		"prefix": "pandas_show_all",
		"body": [
			"with pd.option_context('display.max_rows', None, 'display.max_columns', None):",
			"\tprint(df)"
		],
		"description": "show all data in pandas"
	},
	"pandas read csv": {
		"prefix": "pandas_read_csv",
		"body": [
			"data = pd.read_csv('$1')",
			""
		],
		"description": "read csv"
	},
	//#endregion 

	//#region SCIKIT
	"scikit load iris": {
		"prefix": "scikit_load_iris",
		"body": [
			"# Load the iris dataset",
			"iris = load_iris()",
			"iris_data = pd.DataFrame(iris.data, columns=iris.feature_names)",
			"iris_data['species'] = iris.target",
			""
		],
		"description": "load iris dataset"
	},
	//#endregion END SCIKIT

	
}